import{_ as r,K as t,L as e,W as a}from"./framework-edebdfe1.js";const i={},l=a('<h1 id="gpu开发" tabindex="-1"><a class="header-anchor" href="#gpu开发" aria-hidden="true">#</a> GPU开发</h1><h2 id="_1-gpu-的核心定位" tabindex="-1"><a class="header-anchor" href="#_1-gpu-的核心定位" aria-hidden="true">#</a> 1. GPU 的核心定位</h2><ul><li><strong>高吞吐并行计算</strong>：以数据并行为核心，适合大规模、规则计算（矩阵、向量、像素、张量）。</li><li><strong>与 CPU 的分工</strong>：CPU 负责控制流、复杂分支；GPU 负责密集算术与并行内核。</li><li><strong>典型应用</strong>：图形渲染、科学计算、AI/ML、密码学、视频编解码、金融仿真。</li></ul><h2 id="_2-gpu-架构基础" tabindex="-1"><a class="header-anchor" href="#_2-gpu-架构基础" aria-hidden="true">#</a> 2. GPU 架构基础</h2><h3 id="_2-1-执行模型" tabindex="-1"><a class="header-anchor" href="#_2-1-执行模型" aria-hidden="true">#</a> 2.1 执行模型</h3><ul><li><strong>SIMT / SIMD</strong>：单指令多线程（NVIDIA SIMT），线程以 <strong>warp / wavefront</strong> 为调度单位。</li><li><strong>线程层级</strong>：Grid → Block → Thread（CUDA 术语）。</li><li><strong>分支发散</strong>：同一 warp 内条件分支会串行执行，显著影响性能。</li></ul><h3 id="_2-2-内存层级" tabindex="-1"><a class="header-anchor" href="#_2-2-内存层级" aria-hidden="true">#</a> 2.2 内存层级</h3><ul><li><strong>寄存器（Register）</strong>：最快、最小，线程私有。</li><li><strong>共享内存（Shared / LDS）</strong>：Block 内共享，低延迟。</li><li><strong>全局内存（Global / VRAM）</strong>：容量大、延迟高。</li><li><strong>常量 / 纹理缓存</strong>：只读、针对访问模式优化。</li></ul><blockquote><p>关键原则：<strong>计算密集 &gt; 内存密集；合并访问（Coalescing）</strong>。</p></blockquote><h2 id="_3-主流-gpu-开发平台" tabindex="-1"><a class="header-anchor" href="#_3-主流-gpu-开发平台" aria-hidden="true">#</a> 3. 主流 GPU 开发平台</h2><h3 id="_3-1-cuda-compute-unified-device-architecture" tabindex="-1"><a class="header-anchor" href="#_3-1-cuda-compute-unified-device-architecture" aria-hidden="true">#</a> 3.1 CUDA（Compute Unified Device Architecture）</h3><ul><li><strong>语言</strong>：CUDA C/C++、CUDA Fortran</li><li><strong>生态</strong>：cuBLAS、cuDNN、TensorRT、Thrust</li><li><strong>优势</strong>：成熟、文档齐全、性能最优</li><li><strong>限制</strong>：厂商绑定</li></ul><h3 id="_3-2-opencl-跨厂商" tabindex="-1"><a class="header-anchor" href="#_3-2-opencl-跨厂商" aria-hidden="true">#</a> 3.2 OpenCL（跨厂商）</h3><ul><li><strong>语言</strong>：C-like Kernel</li><li><strong>覆盖</strong>：CPU / GPU / FPGA</li><li><strong>优缺点</strong>：通用但复杂、生态相对弱</li></ul><h3 id="_3-3-vulkan-compute-opengl-compute" tabindex="-1"><a class="header-anchor" href="#_3-3-vulkan-compute-opengl-compute" aria-hidden="true">#</a> 3.3 Vulkan Compute / OpenGL Compute</h3><ul><li><strong>定位</strong>：图形 API 中的计算能力</li><li><strong>优势</strong>：低层、跨平台</li><li><strong>代价</strong>：工程复杂度高</li></ul><h3 id="_3-4-rocm-hip-amd" tabindex="-1"><a class="header-anchor" href="#_3-4-rocm-hip-amd" aria-hidden="true">#</a> 3.4 ROCm / HIP（AMD）</h3><ul><li><strong>定位</strong>：对标 CUDA</li><li><strong>适用</strong>：AMD GPU + HPC</li></ul><h3 id="_3-5-webgpu" tabindex="-1"><a class="header-anchor" href="#_3-5-webgpu" aria-hidden="true">#</a> 3.5 WebGPU</h3><ul><li><strong>语言</strong>：WGSL</li><li><strong>场景</strong>：浏览器 / 跨端</li><li><strong>特点</strong>：安全、现代、潜力大</li></ul><h2 id="_4-编程模型对比" tabindex="-1"><a class="header-anchor" href="#_4-编程模型对比" aria-hidden="true">#</a> 4. 编程模型对比</h2><table><thead><tr><th>维度</th><th>CUDA</th><th>OpenCL</th><th>Vulkan Compute</th><th>WebGPU</th></tr></thead><tbody><tr><td>性能</td><td>★★★★★</td><td>★★★★</td><td>★★★★</td><td>★★★</td></tr><tr><td>易用性</td><td>★★★★</td><td>★★</td><td>★★</td><td>★★★★</td></tr><tr><td>跨平台</td><td>★</td><td>★★★★★</td><td>★★★★★</td><td>★★★★★</td></tr><tr><td>生态</td><td>★★★★★</td><td>★★</td><td>★★★</td><td>★★★</td></tr></tbody></table><h2 id="_5-性能优化方法论" tabindex="-1"><a class="header-anchor" href="#_5-性能优化方法论" aria-hidden="true">#</a> 5. 性能优化方法论</h2><h3 id="_5-1-算法层" tabindex="-1"><a class="header-anchor" href="#_5-1-算法层" aria-hidden="true">#</a> 5.1 算法层</h3><ul><li>提高 <strong>算术强度（FLOPs / Byte）</strong></li><li>降低分支、减少同步</li><li>数据重排以提升局部性</li></ul><h3 id="_5-2-内存层" tabindex="-1"><a class="header-anchor" href="#_5-2-内存层" aria-hidden="true">#</a> 5.2 内存层</h3><ul><li>合并全局内存访问</li><li>使用共享内存缓存热点数据</li><li>避免 bank conflict</li></ul><h3 id="_5-3-并行度" tabindex="-1"><a class="header-anchor" href="#_5-3-并行度" aria-hidden="true">#</a> 5.3 并行度</h3><ul><li>提高 occupancy（寄存器 / block 配置）</li><li>合理选择 block size（常见 128/256/512）</li></ul><h3 id="_5-4-指令级" tabindex="-1"><a class="header-anchor" href="#_5-4-指令级" aria-hidden="true">#</a> 5.4 指令级</h3><ul><li>向量化</li><li>使用 Tensor Core / 专用指令</li></ul><h2 id="_6-调试与分析工具" tabindex="-1"><a class="header-anchor" href="#_6-调试与分析工具" aria-hidden="true">#</a> 6. 调试与分析工具</h2><ul><li><strong>NVIDIA</strong>：Nsight Compute / Nsight Systems / cuda-gdb</li><li><strong>AMD</strong>：rocprof / Radeon GPU Profiler</li><li><strong>通用</strong>：RenderDoc（图形 + compute）</li></ul><h2 id="_7-工程化与部署" tabindex="-1"><a class="header-anchor" href="#_7-工程化与部署" aria-hidden="true">#</a> 7. 工程化与部署</h2><h3 id="_7-1-构建与依赖" tabindex="-1"><a class="header-anchor" href="#_7-1-构建与依赖" aria-hidden="true">#</a> 7.1 构建与依赖</h3><ul><li>CMake + CUDA</li><li>多架构编译（sm_70 / sm_80 / sm_90）</li></ul><h3 id="_7-2-与主程序交互" tabindex="-1"><a class="header-anchor" href="#_7-2-与主程序交互" aria-hidden="true">#</a> 7.2 与主程序交互</h3><ul><li>C/C++ / Rust / Python（FFI / PyCUDA / CuPy）</li><li>异步流（Stream）与事件（Event）</li></ul><h3 id="_7-3-资源管理" tabindex="-1"><a class="header-anchor" href="#_7-3-资源管理" aria-hidden="true">#</a> 7.3 资源管理</h3><ul><li>显存池化</li><li>Kernel 融合（Fusion）</li></ul><h2 id="_8-gpu-与-rust-现代语言" tabindex="-1"><a class="header-anchor" href="#_8-gpu-与-rust-现代语言" aria-hidden="true">#</a> 8. GPU 与 Rust / 现代语言</h2><ul><li><strong>Rust + CUDA</strong>：rust-cuda / FFI</li><li><strong>wgpu + WebGPU</strong>：跨平台计算</li><li><strong>优势</strong>：内存安全、并发语义清晰</li><li><strong>挑战</strong>：生态与调试</li></ul><h2 id="_9-ai-区块链-安全方向结合" tabindex="-1"><a class="header-anchor" href="#_9-ai-区块链-安全方向结合" aria-hidden="true">#</a> 9. AI / 区块链 / 安全方向结合</h2><ul><li><strong>AI</strong>：Tensor Core、低精度（FP16 / BF16 / INT8）</li><li><strong>区块链</strong>：哈希、ZK 证明（MSM / FFT）</li><li><strong>安全</strong>：密码学加速、侧信道防护</li></ul><h2 id="_10-一句话总结" tabindex="-1"><a class="header-anchor" href="#_10-一句话总结" aria-hidden="true">#</a> 10. 一句话总结</h2><blockquote><p><strong>GPU 开发的本质是：用并行换时间，用结构化数据换性能。</strong></p></blockquote>',46),n=[l];function d(h,o){return t(),e("div",null,n)}const u=r(i,[["render",d],["__file","index.html.vue"]]);export{u as default};
