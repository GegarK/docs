const e=JSON.parse('{"key":"v-ac9f32a0","path":"/ai/llm/transformer.html","title":"Transformer","lang":"zh-CN","frontmatter":{"description":"Transformer 是一种基于注意力机制（Attention）的深度学习模型架构，最早由 Google 在 2017 年论文 《Attention Is All You Need》 中提出。它彻底改变了自然语言处理（NLP），并成为当今大模型（如 GPT、BERT、Claude 等）的基础算法框架。 一句话定义：\\r Transformer 是一种通...","head":[["meta",{"property":"og:url","content":"https://deelmind.com/ai/llm/transformer.html"}],["meta",{"property":"og:site_name","content":"極客方舟"}],["meta",{"property":"og:title","content":"Transformer"}],["meta",{"property":"og:description","content":"Transformer 是一种基于注意力机制（Attention）的深度学习模型架构，最早由 Google 在 2017 年论文 《Attention Is All You Need》 中提出。它彻底改变了自然语言处理（NLP），并成为当今大模型（如 GPT、BERT、Claude 等）的基础算法框架。 一句话定义：\\r Transformer 是一种通..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Transformer\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[]}"]]},"headers":[{"level":2,"title":"一、Transformer 解决了什么问题？","slug":"一、transformer-解决了什么问题","link":"#一、transformer-解决了什么问题","children":[]},{"level":2,"title":"二、Transformer 的核心思想","slug":"二、transformer-的核心思想","link":"#二、transformer-的核心思想","children":[{"level":3,"title":"自注意力（Self-Attention）","slug":"自注意力-self-attention","link":"#自注意力-self-attention","children":[]},{"level":3,"title":"可视化","slug":"可视化","link":"#可视化","children":[]}]},{"level":2,"title":"Transformer 算法讲解","slug":"transformer-算法讲解","link":"#transformer-算法讲解","children":[]},{"level":2,"title":"Transformer 代码开发","slug":"transformer-代码开发","link":"#transformer-代码开发","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":1.2,"words":361},"filePathRelative":"ai/llm/transformer.md","copyright":{},"autoDesc":true,"excerpt":""}');export{e as data};
